{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Dataset files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', header=None) \n",
    "test = pd.read_csv('test.csv', header=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary and Dictionary Creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Having transformed the sentences in an analyzable form, we continue by making the vocabulary and creating the corresponding dictionary in which we assign an index for each word of the vocabulary.\n",
    "- In order to create the vocabulary and the dictionary we use the method **vocabulary_builder** from the vocabulary module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocabulary import vocabulary_builder # words, word2idx, idx2word = vocabulary_builder(df,'sent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word2idx, idx2word =  vocabulary_builder(train, 'Sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a few words. To account for unknown words and padding, we'll have to add them to our vocabulary as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39568"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word has an index. For example the word 'on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['game']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_PAD', '_UNK', 's', 'new', 'said', 'reuters', 'ap', 'gt', 'lt', 'year']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Having created the vocabulary, we continue by replacing the words with the corresponding indexes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace words with indeces\n",
    "train_sentences = word2idx_(train, 'Sentence',word2idx)\n",
    "test_sentences = word2idx_(test, 'Sentence',word2idx)\n",
    "valid_sentences = word2idx_(valid, 'Sentence',word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then we pad the sentences with 0s and shortening the lengthy sentences so that the data can be trained in batches to speed the training process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_ = pad_input(train_sentences, seq_len)\n",
    "valid_sentences_ = pad_input(valid_sentences, seq_len)\n",
    "test_sentences_ = pad_input(test_sentences, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Pretrained Word Embeddings (Glove) and Creating the embedding_matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrained_vectors import creating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Loading glove.6B.200d.txt file ...\n",
      "A total of 400000 word vectors loaded.\n",
      "Pre-trained word embeddings cover 96.27% of vocabulary\n",
      "Creating embedding matrix ...\n",
      "Total absent words are 1477 which is 3.73 % of total words\n",
      "Embeding matrix created of shape: (39569, 200)\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "FILE = 'glove.6B.200d.txt'\n",
    "embedding_matrix = creating_matrix(FILE, 200, words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
